{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kaggle_xgboost.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP1Qdvrj9eD6AZrbQJ6cGNg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yonseimath/datascience-biginner-2022-kaggle-competitions/blob/feature%2Fyounghyun/Kaggle_xgboost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "G-7-AN5svVaS"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "from scipy import sparse\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from xgboost import XGBRanker\n",
        "from bisect import bisect"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_train = 10000   # train 횟수 지정\n",
        "\n",
        "def read_notebook(path,id_name):\n",
        "    return (\n",
        "        pd.read_json(path, dtype={'cell_type': 'category', 'source': 'str'})\n",
        "        .assign(id=id_name)                #id는 id_name으로 할당\n",
        "        .rename_axis('cell_id')            #축 이름을 cell_id로 대치\n",
        "    )\n",
        "\n",
        "paths = []           # path 이름의 빈 리스트 생성\n",
        "directory = '../input/AI4Code/train'       #dir 경로 지정\n",
        "for file in os.scandir(directory):      \n",
        "    if file.is_file():\n",
        "        paths.append(file.path)\n",
        "    if len(paths) == num_train:          #paths 길이가 num_train을 넘으면 for 문 종료\n",
        "        break\n",
        "        \n",
        "id_names = []\n",
        "for name in paths:\n",
        "    name = name.split('/')           #path의 name을 /로 split하여 name에 저장\n",
        "    id_n = name[-1].split('.')       #path에서 마지막 요소를 .으로 나눠 id_n에 저장\n",
        "    id_names.append(id_n[0])         #id_n에서 첫 번째 요소를 id_names에 append\n",
        "    \n",
        "print(id_names)\n",
        "print(paths)\n",
        "\n",
        "train_notebooks = []\n",
        "for i in range(len(paths)):\n",
        "    train_notebooks.append(read_notebook(paths[i],id_names[i]))\n",
        "    \n",
        "print(train_notebooks)"
      ],
      "metadata": {
        "id": "hXJIR0ELmVa2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(type(train_notebooks[0]))\n",
        "df = (\n",
        "    pd.concat(train_notebooks)                #concat 함수를 사용하여 인덱스 합침\n",
        "    .set_index('id', append=True)             # id 인덱스로 setting\n",
        "    .swaplevel()                              \n",
        "    .sort_index(level='id', sort_remaining=False)          #index 정렬\n",
        ")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "rr4CbyqkvpUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_orders = pd.read_csv('../input/AI4Code/train_orders.csv',index_col='id',squeeze=True).str.split()      #train_orders 파일 읽어오기"
      ],
      "metadata": {
        "id": "jLL-WQqQvsau"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_orders"
      ],
      "metadata": {
        "id": "V_IXn3f4vuSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_orders_ = df_orders.to_frame().join(            #df_orders에 index별로 group by 하고 join하고 frame으로 저장\n",
        "    df.reset_index('cell_id').groupby('id')['cell_id'].apply(list),             \n",
        "    how='right',                      #right로 join\n",
        ")\n",
        "\n",
        "def get_ranks(base, derived):\n",
        "    return [base.index(d) for d in derived]       #base 인덱스 반환\n",
        "\n",
        "ranks = {}\n",
        "for id_, cell_order, cell_id in df_orders_.itertuples():                        #for문에 id_, cell_order, cell_id 변수 지정\n",
        "    ranks[id_] = {'cell_id': cell_id, 'rank': get_ranks(cell_order, cell_id)}   #ranks의 id_별로 key값과 value값 저장\n",
        "\n",
        "df_ranks = (\n",
        "    pd.DataFrame\n",
        "    .from_dict(ranks, orient='index')                         \n",
        "    .rename_axis('id')                    #axis를 id로 변경\n",
        "    .apply(pd.Series.explode)             \n",
        "    .set_index('cell_id', append=True)    #index를 cell_id로\n",
        ")\n",
        "\n",
        "df_ranks"
      ],
      "metadata": {
        "id": "GBCCbOzLoFcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ancestors = pd.read_csv('../input/AI4Code/train_ancestors.csv', index_col='id')           #ancestors 파일 read\n",
        "df_ancestors"
      ],
      "metadata": {
        "id": "5Jgk8TkfoIpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "siz = 0.1  # size of validation set\n",
        "\n",
        "splitter = GroupShuffleSplit(n_splits=1, test_size=siz, random_state=0)         #분할 반복 횟수를 1로 지정, 0.1 size로 splitter 변수 생성 & 인덱스 제공\n",
        "\n",
        "# Split, keeping notebooks with a common origin (ancestor_id) together\n",
        "ids = df.index.unique('id')                # 중복 없는 id만\n",
        "ancestors = df_ancestors.loc[ids, 'ancestor_id']       #ancestor_id에서 중복 없는 id만\n",
        "ids_train, ids_valid = next(splitter.split(ids, groups=ancestors))      \n",
        "ids_train, ids_valid = ids[ids_train], ids[ids_valid]\n",
        "\n",
        "df_train = df.loc[ids_train, :]\n",
        "df_valid = df.loc[ids_valid, :]"
      ],
      "metadata": {
        "id": "shFMWz2AoJXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training set\n",
        "tfidf = TfidfVectorizer(min_df=0.01)                         #Tfidf 기능의 matrix로 변환\n",
        "X_train = tfidf.fit_transform(df_train['source'].astype(str))  #df_train의 source를 tfidf로 변환하여 x_train에 저장\n",
        "# Rank of each cell within the notebook\n",
        "y_train = df_ranks.loc[ids_train].to_numpy()\n",
        "# Number of cells in each notebook\n",
        "groups = df_ranks.loc[ids_train].groupby('id').size().to_numpy()"
      ],
      "metadata": {
        "id": "RkNOerEMoM_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add code cell ordering\n",
        "X_train = sparse.hstack((\n",
        "    X_train,\n",
        "    np.where(                                                         #where 조건문 cell type이 code면 순서, 그렇지 않으면 0 출력\n",
        "        df_train['cell_type'] == 'code',\n",
        "        df_train.groupby(['id', 'cell_type']).cumcount().to_numpy() + 1,\n",
        "        0,\n",
        "    ).reshape(-1, 1)\n",
        "))\n",
        "print(X_train.shape)"
      ],
      "metadata": {
        "id": "1XkqsvyuoQNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = XGBRanker(                              #XGBRanker 모델 생성\n",
        "    min_child_weight=10,\n",
        "    subsample=0.5,\n",
        "    tree_method='hist',\n",
        ")\n",
        "model.fit(X_train, y_train, group=groups)"
      ],
      "metadata": {
        "id": "j8jkrLy-oRCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation set\n",
        "X_valid = tfidf.transform(df_valid['source'].astype(str))           #valid에 있는 source를 tfidf로 변환(중요한 단어에 가중치) 하여 x_valid에 저장\n",
        "# The metric uses cell ids\n",
        "y_valid = df_orders.loc[ids_valid]                                  \n",
        "\n",
        "X_valid = sparse.hstack((\n",
        "    X_valid,\n",
        "    np.where(                                                          #where 조건문 cell type이 code이면 순서, 그렇지 않으면 0 출력\n",
        "        df_valid['cell_type'] == 'code',\n",
        "        df_valid.groupby(['id', 'cell_type']).cumcount().to_numpy() + 1,\n",
        "        0,\n",
        "    ).reshape(-1, 1)\n",
        "))"
      ],
      "metadata": {
        "id": "4Wp66X8QoV4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = pd.DataFrame({'rank': model.predict(X_valid)}, index=df_valid.index)      # X_valid를 예측한 것을 rank로 하고 index는 df_valid 인덱스로\n",
        "y_pred = (\n",
        "    y_pred\n",
        "    .sort_values(['id', 'rank'])  # Sort the cells in each notebook by their rank.\n",
        "                                  # The cell_ids are now in the order the model predicted.\n",
        "    .reset_index('cell_id')  # Convert the cell_id index into a column.\n",
        "    .groupby('id')['cell_id'].apply(list)  # Group the cell_ids for each notebook into a list.\n",
        ")\n",
        "y_pred.head(10)"
      ],
      "metadata": {
        "id": "vk5A5eepoWgj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb_id = df_valid.index.get_level_values('id').unique()[8]         #중복 없는 id에서 9번째 인자 출력\n",
        "\n",
        "display(df.loc[nb_id])\n",
        "display(df.loc[nb_id].loc[y_pred.loc[nb_id]])\n"
      ],
      "metadata": {
        "id": "bqRrBtOgoYnb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_inversions_slowly(ranks):\n",
        "    inversions = 0\n",
        "    size = len(ranks)\n",
        "    for i in range(size):\n",
        "        for j in range(i+1, size):\n",
        "            if ranks[i] > ranks[j]:\n",
        "                total += 1\n",
        "    return total\n",
        "\n",
        "def count_inversions(a):\n",
        "    inversions = 0\n",
        "    sorted_so_far = []\n",
        "    for i, u in enumerate(a):  \n",
        "        j = bisect(sorted_so_far, u)  \n",
        "        inversions += i - j\n",
        "        sorted_so_far.insert(j, u)  \n",
        "    return inversions\n",
        "\n",
        "def kendall_tau(ground_truth, predictions):\n",
        "    total_inversions = 0  \n",
        "    total_2max = 0  \n",
        "    for gt, pred in zip(ground_truth, predictions):\n",
        "        ranks = [gt.index(x) for x in pred]  # rank predicted order in terms of ground truth\n",
        "        total_inversions += count_inversions(ranks)\n",
        "        n = len(gt)\n",
        "        total_2max += n * (n - 1)\n",
        "    return 1 - 4 * total_inversions / total_2max"
      ],
      "metadata": {
        "id": "JHQergBgoais"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_dummy = df_valid.reset_index('cell_id').groupby('id')['cell_id'].apply(list)\n",
        "kendall_tau(y_valid, y_dummy)                      #y_valid와 y_dummy 사이의 상관계수 출력"
      ],
      "metadata": {
        "id": "RwMN_xt3ofDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kendall_tau(y_valid, y_pred)                       #y_valid와 앞서 구한 y_pred간의 상관계수 출력"
      ],
      "metadata": {
        "id": "7wObpWm3og30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paths = []                                        #앞서 train set으로 진행했던 것들을 test data로 바꾸어 진행\n",
        "directory = '../input/AI4Code/test'\n",
        "for file in os.scandir(directory):\n",
        "    if file.is_file():\n",
        "        paths.append(file.path)\n",
        "    if len(paths) == num_train:\n",
        "        break\n",
        "        \n",
        "id_names = []\n",
        "for name in paths:\n",
        "    name = name.split('/')\n",
        "    id_n = name[-1].split('.')\n",
        "    id_names.append(id_n[0])\n",
        "    \n",
        "# print(id_names)\n",
        "# print(paths)\n",
        "\n",
        "test_notebooks = []\n",
        "for i in range(len(paths)):\n",
        "    test_notebooks.append(read_notebook(paths[i],id_names[i]))\n",
        "    \n",
        "print(test_notebooks[0])"
      ],
      "metadata": {
        "id": "ffJ6VlUboiih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(type(train_notebooks[0]))\n",
        "df_test = (\n",
        "    pd.concat(test_notebooks)\n",
        "    .set_index('id', append=True)\n",
        "    .swaplevel()\n",
        "    .sort_index(level='id', sort_remaining=False)\n",
        ")\n",
        "df_test.head()"
      ],
      "metadata": {
        "id": "jPRB1trTokd_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = tfidf.transform(df_test['source'].astype(str))\n",
        "X_test = sparse.hstack((\n",
        "    X_test,\n",
        "    np.where(\n",
        "        df_test['cell_type'] == 'code',\n",
        "        df_test.groupby(['id', 'cell_type']).cumcount().to_numpy() + 1,\n",
        "        0,\n",
        "    ).reshape(-1, 1)\n",
        "))"
      ],
      "metadata": {
        "id": "aE6Y-2geomM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_infer = pd.DataFrame({'rank': model.predict(X_test)}, index=df_test.index)\n",
        "y_infer = y_infer.sort_values(['id', 'rank']).reset_index('cell_id').groupby('id')['cell_id'].apply(list)\n",
        "y_infer"
      ],
      "metadata": {
        "id": "p10EZdYPon7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_submit = (\n",
        "    y_infer\n",
        "    .apply(' '.join)  # list of ids -> string of ids\n",
        "    .rename_axis('id')\n",
        "    .rename('cell_order')\n",
        ")\n",
        "y_submit"
      ],
      "metadata": {
        "id": "rh6MqfZiopyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_submit.to_csv('submission.csv')"
      ],
      "metadata": {
        "id": "fM8xvijEoriP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}