{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI4Code_EDA_as_Binary_Classification.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOGRHLidt9X27WXSVScNPYq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yonseimath/datascience-biginner-2022-kaggle-competitions/blob/feature%2Fyenakim/yenakim/AI4Code_EDA_as_Binary_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTnINP_3R5Ci"
      },
      "outputs": [],
      "source": [
        "!pip install mglearn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# General\n",
        "import sys, warnings, time, os, copy, gc, re, random, json\n",
        "import pickle as pkl\n",
        "warnings.filterwarnings('ignore')\n",
        "from IPython.display import display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', 100)\n",
        "pd.set_option('display.max_columns', None)\n",
        "# pd.set_option(\"display.max_colwidth\", 10000)\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "from pandas.io.json import json_normalize\n",
        "from pprint import pprint\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "from datetime import datetime, timedelta\n",
        "from scipy import sparse\n",
        "import mglearn\n",
        "\n",
        "# Pre-Processing\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation, TruncatedSVD\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "# from jrstc_util import cleanse_text_new, text_cleaning, clean # 아마 만들어야 하는 함수로 추정\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "import umap\n",
        "\n",
        "# Model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import make_pipeline"
      ],
      "metadata": {
        "id": "mCsp2lTkSrVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuration\n",
        "DEBUG = False\n",
        "PATH_INPUT = Path('../input/AI4Code')\n",
        "SAMPLE_ID = '051d049a469e47'\n",
        "\n",
        "if DEBUG:\n",
        "    NUM_SAMPLE = 10\n",
        "    # NUM_SAMPLE = 1000\n",
        "    \n",
        "else:\n",
        "    NUM_SAMPLE = 2000"
      ],
      "metadata": {
        "id": "GWKdaOD1Suyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dump_load(obj, fileName, mode):\n",
        "    if mode == 'wb':\n",
        "        with open(fileName, mode=mode) as f:\n",
        "            pkl.dump(obj, f)\n",
        "            \n",
        "    elif mode == 'rb':\n",
        "        with open(fileName, mode=mode) as f:\n",
        "            x = pkl.load(f)\n",
        "            \n",
        "            return x\n",
        "            \n",
        "    else:\n",
        "        print('Please give \"wb\" or \"rb\" as mode.')"
      ],
      "metadata": {
        "id": "F9dD2Nv0SwZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_notes(path):\n",
        "    df = pd.read_json(path,\n",
        "                     dtype={'cell_type': 'category', 'source': 'str'}\n",
        "                     )\n",
        "    df = df.assign(id=path.stem).rename_axis('cell_id')\n",
        "    \n",
        "    return df"
      ],
      "metadata": {
        "id": "W_-XEGyLSyGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "listTrainPaths = list((PATH_INPUT / 'train').glob('*.json'))[:NUM_SAMPLE]\n",
        "listTrainNotes = [read_notes(path) for path in tqdm(listTrainPaths)]\n",
        "dfTrain = pd.concat(listTrainNotes)\n",
        "dfTrain = dfTrain.set_index('id', append=True)\n",
        "dfTrain = dfTrain.swaplevel().sort_index(level='id', sort_remaining=False)\n",
        "dfTrain"
      ],
      "metadata": {
        "id": "dTh_rqjZSzsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfOrders = pd.read_csv((PATH_INPUT / 'train_orders.csv'), index_col='id', squeeze=True)\n",
        "dfOrders = dfOrders.str.split()\n",
        "dfOrders"
      ],
      "metadata": {
        "id": "frIH_gwMS1EQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfSample = dfTrain.loc[SAMPLE_ID, :]\n",
        "numCode = dfSample[dfSample['cell_type'] == 'code'].shape[0] # 코드 셀 개수\n",
        "numMark = dfSample[dfSample['cell_type'] == 'markdown'].shape[0] # 마크다운 셀 개수\n",
        "print(f'Notebook {SAMPLE_ID} has {numCode} code cells and {numMark} markdown cells. \\n')\n",
        "dfSample"
      ],
      "metadata": {
        "id": "mJQq5Nn3S2ew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "listOrders = dfOrders.loc[SAMPLE_ID]\n",
        "dfSample.loc[listOrders, :]"
      ],
      "metadata": {
        "id": "MOCkAw8-S37C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del dfSample\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "vSh0AZynS5yM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Column(markdown 앞뒤 셀) 추가"
      ],
      "metadata": {
        "id": "PORFwBXTTUld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfTrain['source'] = dfTrain['source'].progress_apply(cleanse_text_new) # text를 cleanse, 개인 파일"
      ],
      "metadata": {
        "id": "37jIqmASS7wE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "listID = set(dfTrain.reset_index()['id'].tolist()) # 노트북 id들의 집합\n",
        "\n",
        "n = 1\n",
        "for nbid in tqdm(listID):\n",
        "    dfTemp = dfTrain.loc[nbid,:] # 노트북의 source\n",
        "    listMD = dfTemp[dfTemp['cell_type'] == 'markdown'].reset_index()['cell_id'].to_list() # 마크다운 셀의 id만 모아서 list로\n",
        "    listOrders = dfOrders.loc[nbid] # 노트북의 순서\n",
        "    \n",
        "    for mdid in listMD:\n",
        "        pos = listOrders.index(mdid) # 몇 번째에 셀이 위치하는지\n",
        "        \n",
        "        if pos == 0: # 첫번째라면\n",
        "            x = dfTemp.loc[listOrders[:2],:].T # 첫번째 + 두번째 셀\n",
        "            x.columns = ['markdown','code2']\n",
        "            x = x.drop('cell_type')\n",
        "            x['code1'] = 'start' # 첫번째이므로 앞쪽 코드는 start\n",
        "            x = x.reindex(columns=['code1', 'markdown','code2'])\n",
        "            \n",
        "        elif pos == (len(listOrders)-1): # 마지막이라면\n",
        "            x = dfTemp.loc[listOrders[-2:],:].T\n",
        "            x.columns = ['code1', 'markdown']\n",
        "            x = x.drop('cell_type')\n",
        "            x['code2'] = 'end'\n",
        "            \n",
        "        else: # 가운데 위치\n",
        "            x = dfTemp.loc[listOrders[(pos-1):(pos+2)],:].T\n",
        "            x.columns = ['code1', 'markdown','code2']\n",
        "            x = x.drop('cell_type')\n",
        "            \n",
        "            \n",
        "        if n == 1:\n",
        "            dfTrue = x\n",
        "            \n",
        "        else:\n",
        "            dfTrue = pd.concat([dfTrue, x], axis=0)\n",
        "            \n",
        "        n += 1\n",
        "        \n",
        "dfTrue['label'] = 'True'\n",
        "dfTrue"
      ],
      "metadata": {
        "id": "bOorpaSvS9_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfFalse = dfTrue.copy()\n",
        "dfFalse['markdown'] = dfTrue['markdown'].sample(frac=1) # 데이터 셔플\n",
        "dfFalse['label'] = 'False'\n",
        "dfFalse"
      ],
      "metadata": {
        "id": "DfF6mrsXTBO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfAll = pd.concat([dfTrue, dfFalse], axis=0)\n",
        "dfAll['textAll'] = dfAll['code1'] + ' ' + dfAll['markdown'] + ' ' + dfAll['code2']"
      ],
      "metadata": {
        "id": "fPCAyrfuTC0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 코사인 유사도"
      ],
      "metadata": {
        "id": "LumpDmjmTSLz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectCode1 = vectorizer.transform(dfAll['code1']) # 벡터로 바꿈\n",
        "vectMD = vectorizer.transform(dfAll['markdown'])\n",
        "vectCode2 = vectorizer.transform(dfAll['code2'])"
      ],
      "metadata": {
        "id": "55NJsxY2TD7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(dfAll.shape[0]):\n",
        "    cosSim1 = cosine_similarity(vectCode1[i], vectMD[i])\n",
        "    cosSim2 = cosine_similarity(vectMD[i], vectCode2[i])\n",
        "    cosSimRow = np.append(cosSim1, cosSim2).reshape(-1,2)\n",
        "    if i == 0:\n",
        "        cosSimAll = cosSimRow\n",
        "    else:\n",
        "        cosSimAll = np.concatenate([cosSimAll, cosSimRow], 0)\n",
        "\n",
        "dfCosSim = pd.DataFrame(data=cosSimAll, columns=['cos_sim1', 'cos_sim2'])\n",
        "dfAll = pd.concat([dfAll, dfCosSim], axis=1)"
      ],
      "metadata": {
        "id": "r5bYjS2QTIKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "sns.scatterplot(data=dfAll, x='cos_sim1', y='cos_sim2', hue='label')"
      ],
      "metadata": {
        "id": "uQZ2ZQnsTJRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfAll.to_csv('dfAll.csv')\n",
        "dfAll"
      ],
      "metadata": {
        "id": "8hE9uHtsTKOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FouaiugyTLyw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}