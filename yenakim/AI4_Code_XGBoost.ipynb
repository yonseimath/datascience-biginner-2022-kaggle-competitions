{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI4_Code_XGBoost.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPxQvsdvuPpFMTZT6X8jeDh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yonseimath/datascience-biginner-2022-kaggle-competitions/blob/feature%2Fyenakim/yenakim/AI4_Code_XGBoost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tth1Ivc5NbKA"
      },
      "outputs": [],
      "source": [
        "siz = 0.1  # size of validation set\n",
        "\n",
        "splitter = GroupShuffleSplit(n_splits=1, test_size=siz, random_state=0)\n",
        "\n",
        "# Split, keeping notebooks with a common origin (ancestor_id) together\n",
        "ids = df.index.unique('id')\n",
        "ancestors = df_ancestors.loc[ids, 'ancestor_id']\n",
        "ids_train, ids_valid = next(splitter.split(ids, groups=ancestors))\n",
        "ids_train, ids_valid = ids[ids_train], ids[ids_valid]\n",
        "\n",
        "df_train = df.loc[ids_train, :]\n",
        "df_valid = df.loc[ids_valid, :]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train"
      ],
      "metadata": {
        "id": "7aQT15_3NdTa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training set\n",
        "tfidf = TfidfVectorizer(min_df=0.01)\n",
        "X_train = tfidf.fit_transform(df_train['source'].astype(str))\n",
        "# Rank of each cell within the notebook\n",
        "y_train = df_ranks.loc[ids_train].to_numpy()\n",
        "# Number of cells in each notebook\n",
        "groups = df_ranks.loc[ids_train].groupby('id').size().to_numpy()"
      ],
      "metadata": {
        "id": "6drs5Us2NenQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train)"
      ],
      "metadata": {
        "id": "EpW-XBkENgfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add code cell ordering\n",
        "X_train = sparse.hstack(( # 희소 행렬을 수평으로 쌓기\n",
        "    X_train,\n",
        "    np.where(\n",
        "        df_train['cell_type'] == 'code',\n",
        "        df_train.groupby(['id', 'cell_type']).cumcount().to_numpy() + 1,\n",
        "        0,\n",
        "    ).reshape(-1, 1) # Code 셀이면 노트북 안 셀의 개수를, Markdown 셀이면 0을 넣는다\n",
        "))\n",
        "print(X_train.shape)"
      ],
      "metadata": {
        "id": "RwFSJc5jNjZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = XGBRanker(\n",
        "    min_child_weight=10,\n",
        "    subsample=0.5,\n",
        "    tree_method='hist',\n",
        ")\n",
        "model.fit(X_train, y_train, group=groups)"
      ],
      "metadata": {
        "id": "yVD5tmiQNj3w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation set\n",
        "X_valid = tfidf.transform(df_valid['source'].astype(str))\n",
        "# The metric uses cell ids\n",
        "y_valid = df_orders.loc[ids_valid]\n",
        "\n",
        "X_valid = sparse.hstack((\n",
        "    X_valid,\n",
        "    np.where(\n",
        "        df_valid['cell_type'] == 'code',\n",
        "        df_valid.groupby(['id', 'cell_type']).cumcount().to_numpy() + 1,\n",
        "        0,\n",
        "    ).reshape(-1, 1)\n",
        "))"
      ],
      "metadata": {
        "id": "AzTLH4fSNmht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_valid.index"
      ],
      "metadata": {
        "id": "t3ZYZaKENohX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = pd.DataFrame({'rank': model.predict(X_valid)}, index=df_valid.index)\n",
        "y_pred = (\n",
        "    y_pred\n",
        "    .sort_values(['id', 'rank'])  # Sort the cells in each notebook by their rank.\n",
        "                                  # The cell_ids are now in the order the model predicted.\n",
        "    .reset_index('cell_id')  # Convert the cell_id index into a column.\n",
        "    .groupby('id')['cell_id'].apply(list)  # Group the cell_ids for each notebook into a list.\n",
        ")\n",
        "y_pred.head(10)"
      ],
      "metadata": {
        "id": "GQUEBYeZNpz4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_valid.index.get_level_values('id')"
      ],
      "metadata": {
        "id": "5snFPQKvNrUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_valid.index.get_level_values('id').unique()[8]"
      ],
      "metadata": {
        "id": "-wbS7ITVNsiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb_id = df_valid.index.get_level_values('id').unique()[8] # 잘 배열됐는지 확인\n",
        "\n",
        "display(df.loc[nb_id])\n",
        "display(df.loc[nb_id].loc[y_pred.loc[nb_id]])"
      ],
      "metadata": {
        "id": "B75PNgxoNtx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_inversions_slowly(ranks):\n",
        "    inversions = 0\n",
        "    size = len(ranks)\n",
        "    for i in range(size):\n",
        "        for j in range(i+1, size):\n",
        "            if ranks[i] > ranks[j]:\n",
        "                total += 1\n",
        "    return total\n",
        "\n",
        "def count_inversions(a):\n",
        "    inversions = 0\n",
        "    sorted_so_far = []\n",
        "    for i, u in enumerate(a):  \n",
        "        j = bisect(sorted_so_far, u)  \n",
        "        inversions += i - j\n",
        "        sorted_so_far.insert(j, u)  \n",
        "    return inversions\n",
        "\n",
        "# 켄달 상관계수\n",
        "def kendall_tau(ground_truth, predictions):\n",
        "    total_inversions = 0  \n",
        "    total_2max = 0  \n",
        "    for gt, pred in zip(ground_truth, predictions):\n",
        "        ranks = [gt.index(x) for x in pred]  # rank predicted order in terms of ground truth\n",
        "        total_inversions += count_inversions(ranks)\n",
        "        n = len(gt)\n",
        "        total_2max += n * (n - 1)\n",
        "    return 1 - 4 * total_inversions / total_2max"
      ],
      "metadata": {
        "id": "fjU9rZa2Nu4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_valid"
      ],
      "metadata": {
        "id": "ahysGfs2Nw03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_dummy"
      ],
      "metadata": {
        "id": "jMXPr7MVNyN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_dummy = df_valid.reset_index('cell_id').groupby('id')['cell_id'].apply(list)\n",
        "kendall_tau(y_valid, y_dummy) # dummy : 정렬 X, valid : 정답"
      ],
      "metadata": {
        "id": "ptQTqiMQNzTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kendall_tau(y_valid, y_pred) # pred : 예측"
      ],
      "metadata": {
        "id": "9nn2Z_WYN0ef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paths = []\n",
        "directory = '../input/AI4Code/test'\n",
        "for file in os.scandir(directory):\n",
        "    if file.is_file():\n",
        "        paths.append(file.path)\n",
        "    if len(paths) == num_train:\n",
        "        break\n",
        "        \n",
        "id_names = []\n",
        "for name in paths:\n",
        "    name = name.split('/')\n",
        "    id_n = name[-1].split('.')\n",
        "    id_names.append(id_n[0])\n",
        "    \n",
        "# print(id_names)\n",
        "# print(paths)\n",
        "\n",
        "test_notebooks = []\n",
        "for i in range(len(paths)):\n",
        "    test_notebooks.append(read_notebook(paths[i],id_names[i]))\n",
        "    \n",
        "print(test_notebooks[0])"
      ],
      "metadata": {
        "id": "J3ymjI22N1vn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(type(train_notebooks[0]))\n",
        "df_test = (\n",
        "    pd.concat(test_notebooks)\n",
        "    .set_index('id', append=True)\n",
        "    .swaplevel()\n",
        "    .sort_index(level='id', sort_remaining=False)\n",
        ")\n",
        "df_test.head()"
      ],
      "metadata": {
        "id": "A7i8Mf86N33D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = tfidf.transform(df_test['source'].astype(str))\n",
        "X_test = sparse.hstack((\n",
        "    X_test,\n",
        "    np.where(\n",
        "        df_test['cell_type'] == 'code',\n",
        "        df_test.groupby(['id', 'cell_type']).cumcount().to_numpy() + 1,\n",
        "        0,\n",
        "    ).reshape(-1, 1)\n",
        "))"
      ],
      "metadata": {
        "id": "Eh80eqiZN5fl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_infer = pd.DataFrame({'rank': model.predict(X_test)}, index=df_test.index)\n",
        "y_infer = y_infer.sort_values(['id', 'rank']).reset_index('cell_id').groupby('id')['cell_id'].apply(list)\n",
        "y_infer"
      ],
      "metadata": {
        "id": "u7lfAkjAN6xL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_submit = (\n",
        "    y_infer\n",
        "    .apply(' '.join)  # list of ids -> string of ids\n",
        "    .rename_axis('id')\n",
        "    .rename('cell_order')\n",
        ")\n",
        "y_submit"
      ],
      "metadata": {
        "id": "nj-ZIxFEN-CF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_submit.to_csv('submission.csv')"
      ],
      "metadata": {
        "id": "mTT0r555N_Wl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}